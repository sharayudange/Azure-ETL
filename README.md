# Azure-ETL-AmazonSalesAnalysis
# Overview
This project is centered around developing an extensive Extract, Transform, and Load (ETL) pipeline utilizing the advanced capabilities of Microsoft Azure. The pipeline efficiently retrieves data from Azure Blob Storage, performs necessary transformations using Azure Databricks and Azure Data Factory, and stores it in Azure Data Lake.

# Dataset
The dataset used in this project contains detailed information on e-commerce sales transactions for Amazon India, including customer demographics, product categories, order details, payment methods, and shipping information, allowing for in-depth analysis of sales patterns, customer behavior, and profitability in an e-commerce setting


# Pipeline Workflow

# Data Extraction & Storage
Raw sales data is extracted and stored in Azure Blob Storage containers.

# ETL Pipeline Creation
A structured ETL pipeline is designed to automate data movement and transformations.

# Loading into Data Lake
The extracted data is ingested into an Azure Data Lake for scalable storage.

# Data Transformation using Databricks
Transformation tasks, such as data cleaning, feature engineering, and aggregations, are performed using Databricks (Apache Spark)

# Loading Processed Data Back to Data Lake
The transformed data is stored back in Azure Data Lake for further processing.

# Loading into Azure Synapse Analytics
Final transformed data is loaded into Azure Synapse Analytics for SQL-based querying and analysis.

# Technologies Used
# Azure Blob Storage (for raw data storage)
# Azure Data Lake (for data management)
# Azure Data Factory (for building the ETL pipeline)
# Databricks (for data transformation using Spark)
# Azure Synapse Analytics (for SQL-based data analysis)

                                                                                                                                                                                      
